[{"categories":["设计模式"],"content":"在软件开发中，我们或多或少知道一些经典的设计原则。保持对原则的警醒比应用了多少原则更重要。 ","date":"2021-07-01","objectID":"/design-principles/:0:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"1 开闭原则(Open-Closed Principle, OCP) OCP是指一个软件实体，如类、模块和函数应该对扩展开放，对修改关闭。所谓的开闭，也正是对扩展和修改两个行为的一个原则。强调的是用抽象架构框架，用实现扩展细节。可以提高软件系统的可复用性及可维护性。开闭原则，是面向对象设计中最基础的设计原则。它指导我们如何建立稳定灵活的系统，例如：我们版本更新，我尽可能不修改源代码，但是可以增加新功能。实现开闭原则的核心思想就是面向抽象编程。 ","date":"2021-07-01","objectID":"/design-principles/:1:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"2 依赖倒置原则(Dependence Inversion Principle, DIP) DIP是指设计代码结构时，高层模块不应该依赖底层模块，二者都应该依赖其抽象。抽象不应该依赖细节，细节应该依赖抽象。通过依赖倒置可以减少类与类之间的耦合性，提高系统的稳定性，提高代码的可读性和可维护性，并能够降低修改程序所造成的风险。 ","date":"2021-07-01","objectID":"/design-principles/:2:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"3 单一职责原则(Simple Responsibility Principle, SRP) SRP是指不要存在多于一个导致类变更的原因。假设我们有一个Class负责两个职责，一旦发生需求变更，修改其中一个职责的逻辑代码，有可能会导致另一个职责的功能发生故障。这样一来，这个Class存在两个导致类变更的原因。因此我们需要给两个职责分别用两个Class来实现，进行解耦，可以降低类的复杂度，提高类的可读性，提高系统的可维护性，降低变更引起的风险。总体来说就是一个类、接口、方法只负责一项职责。 ","date":"2021-07-01","objectID":"/design-principles/:3:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"4 接口隔离原则(Interface Segregation Principle, ISP) ISP是指用多个专门的接口，而不使用单一的总接口，客户端不应该依赖它不需要的接口。这个原则指导我们在设计接口时应当注意以下几点： 一个类对一类的依赖应该建立在最小的接口之上。 建立单一接口，不要建立庞大臃肿的接口。 尽量细化接口，接口中的方法尽量少(不是越少越好，一定要适度)。 接口隔离原则符合我们常说的高内聚低耦合的设计思想，从而使得类具有很好的可读性、可扩展性和可维护性。 ","date":"2021-07-01","objectID":"/design-principles/:4:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"5 迪米特原则(Law of Demeter, LoD) LoD是指一个对象应该对其他对象保持最少的了解，又叫最少知道原则(Least Knowledge Principle, LKP)，尽量降低类与类之间的耦合。迪米特原则主要强调只和朋友交流，不和陌生人说话。出现在成员变量、方法的输入和输出参数中的类都可以称之为朋友类，而出现在方法体内部的类不属于朋友类。 ","date":"2021-07-01","objectID":"/design-principles/:5:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"6 里氏替换原则(Liskov Substitution Principle, LSP) LSP是指如果对每一个类型为T1的对象o1，都有类型为T2的对象o2，使得以T1定义的所有程序P在所有对象o1都替换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。 引申含义：子类可以扩展父类的功能，但不能改变父类原有的功能。 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件(即方法的入参)要比父类方法的输入参数更宽松。 当子类的方法实现父类的方法时(重写/重载或实现抽象方法)，方法的后置条件(即方法的返回值)要比父类更严格或相等。 优点： 约束继承泛滥，开闭原则的一种体现。 加强程序的健壮性，同时变更时也可以做到非常好的兼容性，提高程序的维护性、扩展性。降低需求变更时引入的风险。 ","date":"2021-07-01","objectID":"/design-principles/:6:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"7 合成复用原则(Composite/Aggregate Reuse Principle, CARP) CARP是指尽量使用对象组合(has-a)或聚合(contains-a)，而不是继承关系达到软件复用的目的。可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少。 ","date":"2021-07-01","objectID":"/design-principles/:7:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["设计模式"],"content":"8 设计原则总结 封装变化。 多用组合，少用继承。 针对接口编程，不针对实现编程。 为交互对象之间的松耦合设计而努力。 对扩展开放，对修改关闭。 依赖抽象，不要依赖具体类。 只和朋友谈。 将决策权放在高层模块中，以便决定如何以及何时调用低层模块。 类应该只有一个改变的理由。 子类可以扩展父类的功能，但不能改变父类原有的功能。 保持对原则的警醒比应用了多少原则更重要。 ","date":"2021-07-01","objectID":"/design-principles/:8:0","tags":["设计模式","设计原则"],"title":"七大软件设计原则","uri":"/design-principles/"},{"categories":["kafka","distributed"],"content":"Kafka分布式事件流处理平台是一个开源的分布式事件流平台，被数千家公司用于高性能数组管道、流分析、数据集成和任务关键型应用程序。 Kafka是什么？ Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. ","date":"2021-04-10","objectID":"/kafka-introduction/:0:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Kafka的使用场景 消息系统(Messaging) 网站活动跟踪(Website Activity Tracking) 数据指标(Metrics) 日志聚合(Log Aggregation) 流处理(Stream Processing) 事件驱动(Event Sourcing) 日志存储(Commit Log) 以上信息源自官网, 详见: Kafka Use Cases 警告 本文对Kafka的分析均源自分布式消息系统的场景下 ","date":"2021-04-10","objectID":"/kafka-introduction/:1:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Kafka基本术语介绍 Broker 一个单独的Kafka server就是一个Broker，kafka集群由多个Broker组成 Producer 生产者，主要工作是往Broker发送(push)消息 Consumer 消费者，主要工作是从Broker拉取(pull)消息 Topic 主题，存储消息的逻辑概念。可以理解为rabbitMQ中的queue Partition 分区，每个Topic可以划分成多个分区 Log 分区上存储数据的日志文件，生产者将消息写入分区时，实际上就是写入对应的Log中 Segment 段，Partition里的log文件会划分成多个段 Consumer Group Kafka中多个Consumer组成一个Consumer Group，一个Consumer必须只能属于一个Consumer Group Replica 副本，Kafka实现高可用的机制，每个Topic至少有一个副本 ","date":"2021-04-10","objectID":"/kafka-introduction/:2:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Kafka架构拓扑图 Kafka Architecture-Diagram ","date":"2021-04-10","objectID":"/kafka-introduction/:3:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Kafka架构初识 Kafka作为分布式消息中间件，可以很好的替代传统的消息系统。与大多数消息系统相比，具有更好的吞吐量、内置分区、复制和容错能力，这使它在大规模数据应用场景有着明显的性能优势。 最简单的消息系统一般都会包含：生产者producer、消费者consumer、队列queue。如下图所示，仅存一个队列的情况下，生产者先向队列里投递消息，然后消费者再从队列里消费消息。 MQ Queue 先不谈Kafka的架构如何，单就上图最简单的场景，如果要提高效率，该怎么做？ 在解答这个问题之前，先考虑一下以上mq模型存在哪些缺点： 随着消息量增大，当queue承载的数据量过大时，影响读写性能，同时queue服务也可能宕机 当有多个消费者同时消费同一队列里的数据时，需要保证消息分配正确及维护消费位移，而这个过程也是非常耗性能的 当生产者发送消息的速度比消费者消费消息的速度快时，queue服务一直向消费者push消息，消费者可能承受不了压力而宕机 要解决以上问题，通过数据分块、多线程的方式可以缓解，但治标不治本。那么来看看Kafka是如何解决的吧。 ","date":"2021-04-10","objectID":"/kafka-introduction/:4:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Topic \u0026 Partition \u0026 Segment 顾名思义，主题。Kafka存储消息的逻辑概念，可以简单理解为上面所说的queue。生产者负责向Topic里send消息，消费者负责从Topic里pull消息然后处理。 为了解决一个Topic里的数据文件过大导致的读写性能问题，Kafka将其划分为多个Partition。如下图所示： Topic \u0026 Partition 生产者发送消息的时候会按照策略，将消息发送至不同的Partition,发往每个Partiton里的消息会在分区内对应一个偏移量offset且均从0开始依次递增。Kafka保证一个Partiton内的消息是有序的，但无法保证一个Topic内数据的顺序性。如下图所示： Partition 虽然将Topic划分多个Partition可以避免数据过于集中导致的问题，但当Partition中数据过大的时候还是会影响读写性能。因此Kafka再将Partition在物理层面下，通过文件大小、时间等策略细分多段segment，当该段文件大小或时间满足要求，则生成下一段文件数据，每段下均有其对应的索引文件来加速查询。而数据写入的方式则是顺序磁盘IO及文件追加写的形式。 ","date":"2021-04-10","objectID":"/kafka-introduction/:4:1","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Pull vs Push 首先考虑的一个问题，消费者是应该从Broker那里获取数据，还是Broker应该将数据推给消费者 push: 当生产者发送消息的速度比消费者消费消息的速度快时，Broker服务一直向消费者push消息，消费者可能承受不了压力而宕机。但这样的好处是，Broker不容易积压消息。 pull: 当生产者发送消息的速度比消费者消费消息的速度快时，消费者只是消费落后，后面可能赶上。消息积压在Broker上 ","date":"2021-04-10","objectID":"/kafka-introduction/:4:2","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Replica机制 在分布式系统中，高可用是一个避不开的问题，而Kafka则是通过副本机制实现高可用。 创建Topic时可以指定副本数(至少一个副本)。当创建一个Topic，指定3个分区和3个副本。这样每个分区都有3个副本，Kafka根据一定策略，选出每个分区里的leader和follower，然后尽力确保每个分区的leader落在不同的Broker上。当有Broker宕机的时候，就会触发分区副本选举机制，选举出新的leader。如下图所示： Broker ","date":"2021-04-10","objectID":"/kafka-introduction/:4:3","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"ISR \u0026 HW \u0026 LEO AR、ISR、OSR是什么？ AR(Assigned Replicas): 分区中的所有副本 ISR(In-Sync Replicas): 所有与leader副本保持一定程度同步的副本 OSR(Out-of-Sync Replicas): 与leader副本同步滞后过多的副本 由此可见，AR = ISR + OSR leader副本负责维护和跟踪 ISR 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。如果 OSR 集合中有follower副本追上了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有 ISR 集合里的副本才有资格选举为新的leader HW、LEO是什么？ HW(High Watermark): 高水位，它标识了一个特定的消息偏移量offset，消费者只能拉取到这个offset之前的消息 LEO(Log End Offset): 它标识当前日志文件中下一条待写入消息的offset Partition HW LEO 由此可见，Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。 事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种复制方式极大的影响了性能。而异步复制的方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就被认为已经提交成功。在这种情况下，如果follower副本都落后leader副本，突然leader副本宕机，则会造成数据丢失。 Kafka使用的这种ISR的方式则有效的权衡了数据可靠性和性能之间的关系。 ","date":"2021-04-10","objectID":"/kafka-introduction/:4:4","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Producer 主要工作是向Topic发送消息。但由于副本机制，生产者发送消息怎么样算发送成功呢？在一般的分布式系统中一般采用过半提交的方式确保，既一半以上的副本确认成功才算消息提交成功，但Kafka中并未提供这种机制。Kafka可以通过以下参数配置保障： Producer提供配置acks参数 acks=0 生产者只要将消息发送出去，无需等待任何副本的确认，即算发送成功。此方式吞吐量最大、性能最好，但kafka服务抖动时容易丢消息 acks=1 默认。生产者将消息发送出去，只需副本中的leader确认，即算发送成功。此方式吞吐量和性能优秀，但当leader挂时会造成小部分消息丢失 acks=all 生产者将消息发送出去，需要ISR中的副本全部确认，即算发送成功。此方式吞吐量和性能差，但稳定性最高，消息不容易丢失 Broker 提供配置replica.lag.time.max.ms参数 如果一个follower没有发送任何fetch请求，或者至少在这段时间内没有消耗到leaders日志结束偏移量，那么leader将从 ISR 中删除follower ","date":"2021-04-10","objectID":"/kafka-introduction/:5:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Consumer 在Kafka中，1个Partition只能被1个消费线程消费。消费线程主动pull数据，而非Kafka Server主动push数据，这样消费者可以根据自己的消费能力消费数据。如果有消息堆积，也方便开发人员对消费者及时管理。 如果消费线程大于分区数，则多余的消费线程将空闲；如果消费线程小于分区数，则有部分消费线程将消费多个分区的数据；如果消费线程等于分区数，则刚刚好一个消费线程对应一个分区，这也是最理想的情况。 这样做的好处是offset偏移量方便管理且简单，消费数据的分配及提交offset无需事务保障，也提高了效率。 Partition Consumer ","date":"2021-04-10","objectID":"/kafka-introduction/:6:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"提交offset 由于消费者是主动pull数据，因此每个分区的offset由对应的消费者线程维护，每个消费线程需要记录消费到当前分区的偏移量offset。 在早起Kafka的版本中，每个分区的offset由对应的消费线程维护在zk上。但由于zookeeper的单节点写的特性(只有leader才能处理写请求)，所以zookeeper不适合大量数据的频繁写。 之后在Kafka的版本中，每个分区的offset由对应的消费线程维护在__consumer_offset主题中。 ","date":"2021-04-10","objectID":"/kafka-introduction/:6:1","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"结语 以上就是Kafka在整个架构之美的其中一部分，设计还是相当巧妙的。当然涉及到Kafka的东西还有很多。 比如，Kafka在之后版本中逐步在降低对zookeeper的依赖。例如分区副本的选举，在之前的版本中，都是依赖zookeeper操作的。但如果Broker上的Topic过多，一旦Broker宕机将会触发大量Watcher事件，从而引起惊群效应，会导致巨大的服务器性能消耗和网络冲击。因为zookeeper的特性，Kafka选择将各种选举机制都依靠自己解决。 Kafka值得考究、学习和思考的地方还有很多，之后会一一整理分享出来。 ","date":"2021-04-10","objectID":"/kafka-introduction/:7:0","tags":["kafka","mq"],"title":"Kafka初识之架构之美","uri":"/kafka-introduction/"},{"categories":["kafka","distributed"],"content":"Kafka分布式事件流处理平台 本文将介绍kafka伪集群的搭建。 环境说明 Ubuntu-64bit-20.04.2 java-11.0.10 zookeeper-3.7.0 Zookeeper集群搭建 kafka-2.7.0 ","date":"2021-04-10","objectID":"/kafka-build/:0:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"下载和解压kafka Kafka官方下载 以路径/home/micro/kafka为例 $ cd /home/micro/kafka $ wget https://downloads.apache.org/kafka/2.7.0/kafka_2.13-2.7.0.tgz $ tar -xzvf kafka_2.13-2.7.0.tgz ","date":"2021-04-10","objectID":"/kafka-build/:1:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"创建kafka日志文件夹 $ mkdir kafka-logs1 kafka-logs2 kafka-logs3 ","date":"2021-04-10","objectID":"/kafka-build/:2:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"修改配置文件 复制3个配置文件 $ cd kafka_2.13-2.7.0/config/ $ cp server.properties server1.properties $ cp server.properties server2.properties $ cp server.properties server3.properties 修改配置文件中的broker.id分别为1、2、3 listeners 端口分别为9092、9093、9094 log.dirs 分别设置为kafka-logs1、kafka-logs2、kafka-logs3 server1.properties的关键配置： broker.id=1 listeners=PLAINTEXT://192.168.90.5:9092 log.dirs=/home/micro/kafka/kafka-logs1 # 每个topic的默认partitions数 # 建议配置大于1,否则__consumer_offset分区为1时,broker挂掉无法恢复时会无法消费 num.partitions=3 # 是否能自动创建topic,该参数生产环境建议关闭 auto.create.topics.enable=false zookeeper.connect=192.168.90.4:2181,192.168.90.4:2182,192.168.90.4:2183 server2.properties的关键配置： broker.id=2 listeners=PLAINTEXT://192.168.90.5:9093 log.dirs=/home/micro/kafka/kafka-logs2 num.partitions=3 auto.create.topics.enable=false zookeeper.connect=192.168.90.4:2181,192.168.90.4:2182,192.168.90.4:2183 server3.properties的关键配置： broker.id=3 listeners=PLAINTEXT://192.168.90.5:9094 log.dirs=/home/micro/kafka/kafka-logs3 num.partitions=3 auto.create.topics.enable=false zookeeper.connect=192.168.90.4:2181,192.168.90.4:2182,192.168.90.4:2183 ","date":"2021-04-10","objectID":"/kafka-build/:3:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"启动kafka 启动kafka之前，请确认zk服务已启动 $ cd kafka_2.13-2.7.0/bin/ $ ./kafka-server-start.sh -daemon ../config/server1.properties $ ./kafka-server-start.sh -daemon ../config/server2.properties $ ./kafka-server-start.sh -daemon ../config/server3.properties ","date":"2021-04-10","objectID":"/kafka-build/:4:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"验证集群是否搭建成功 ","date":"2021-04-10","objectID":"/kafka-build/:5:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"集群下创建Topic 创建一个名为kafka-test的topic $ ./kafka-topics.sh --create --topic kafka-test --bootstrap-server 192.168.90.5:9092 查看已创建的topic $ ./kafka-topics.sh --list kafka-test --bootstrap-server 192.168.90.5:9092 删除topic $ ./kafka-topics.sh --delete --topic kafka-test --bootstrap-server 192.168.90.5:9092 ","date":"2021-04-10","objectID":"/kafka-build/:5:1","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"集群下启动Consumer 在一个新的终端中: $ ./kafka-console-consumer.sh --bootstrap-server 192.168.90.5:9092,192.168.90.5:9093,192.168.90.5:9094 --topic kafka-test ","date":"2021-04-10","objectID":"/kafka-build/:5:2","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"集群下启动Producer 在一个新的终端中： $ ./kafka-console-producer.sh --bootstrap-server 192.168.90.5:9092,192.168.90.5:9093,192.168.90.5:9094 --topic kafka-test ","date":"2021-04-10","objectID":"/kafka-build/:5:3","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"集群下Producer终端下发送消息 在生产者窗口输入任意数据，观察Consumer窗口的变化 ","date":"2021-04-10","objectID":"/kafka-build/:5:4","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["kafka","distributed"],"content":"结语 以上是搭建kafka伪集群的全过程，真正集群的搭建也均类似。 ","date":"2021-04-10","objectID":"/kafka-build/:6:0","tags":["kafka","mq"],"title":"Kafka集群搭建(伪集群)","uri":"/kafka-build/"},{"categories":["zookeeper","distributed"],"content":"Zookeeper分布式协调组件 本文将介绍zookeeper伪集群的搭建。 环境说明 Ubuntu-64bit-20.04.2 java-11.0.10 zookeeper-3.7.0 ","date":"2021-04-10","objectID":"/zookeeper-build/:0:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"下载zookeeper zookeeper官方下载 以安装路径/home/micro/zookeeper为例 $ cd /home/micro/zookeeper $ wget https://downloads.apache.org/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz ","date":"2021-04-10","objectID":"/zookeeper-build/:1:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"解压 tar -xzvf apache-zookeeper-3.7.0-bin.tar.gz ","date":"2021-04-10","objectID":"/zookeeper-build/:2:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"创建zookeeper独立目录 $ # 复制zk $ cp apache-zookeeper-3.7.0-bin zookeeper01 -rf $ cp apache-zookeeper-3.7.0-bin zookeeper02 -rf $ cp apache-zookeeper-3.7.0-bin zookeeper03 -rf $ # 创建数据文件夹 $ mkdir zookeeper01/data $ mkdir zookeeper02/data $ mkdir zookeeper03/data $ # 依次进入zk目录创建zoo.cfg $ cp zookeeper01/conf/zoo_sample.cfg zookeeper01/conf/zoo.cfg $ cp zookeeper02/conf/zoo_sample.cfg zookeeper02/conf/zoo.cfg $ cp zookeeper03/conf/zoo_sample.cfg zookeeper03/conf/zoo.cfg ","date":"2021-04-10","objectID":"/zookeeper-build/:3:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"指定id zookeeper启动的时候，会在它的数据目录下寻找id文件，以便知道它自己在集群中的编号。 $ echo 1 \u003e zookeeper01/data/myid $ echo 2 \u003e zookeeper02/data/myid $ echo 3 \u003e zookeeper03/data/myid ","date":"2021-04-10","objectID":"/zookeeper-build/:4:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"修改zookeeper配置 以zookeeper01为例 进入配置文件后，需要额外重点关注以下几个配置： dataDir=/home/micro/zookeeper/zookeeper01/data # zk服务端口 3个节点分别是2181、2182、2183 clientPort=2181 server.1=IP:1111:2221 server.2=IP:1112:2222 server.3=IP:1113:2223 其他节点的配置文件类似，保证每个zk服务器的数据目录和端口不一致(伪集群需要)，集群配置需一致。 zk集群配置格式: server.A=B:C:D[:observer] A 是一个数字，表示这个是第几个zk服务器，这个数字后面集群选举leader的时候会用到 B 是这个zk服务器的IP地址，也可以设置为主机名 C 是端口号，用来集群成员的信息交换，表示这个服务器与集群中的leader服务器交换信息的端口 D 是在leader挂掉时专门用来进行选举leader所用的端口 observer 代表这台zk节点只作为观察者存在，不参与leader选举，非必需 ","date":"2021-04-10","objectID":"/zookeeper-build/:5:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"启动zookeeper $ ./zookeeper01/bin/zkServer.sh start ./zookeeper01/conf/zoo.cfg $ ./zookeeper02/bin/zkServer.sh start ./zookeeper02/conf/zoo.cfg $ ./zookeeper03/bin/zkServer.sh start ./zookeeper03/conf/zoo.cfg ","date":"2021-04-10","objectID":"/zookeeper-build/:6:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"验证 验证是否启动成功及集群是否生效。 连接其中一个zk节点，并创建数据节点 连接其他zk节点，看数据是否同步到了其他节点。若同步成功，则集群搭建成功 以下是验证集群是否生效用到命令： 启动客户端连接其中一个节点： $ ./zookeeper01/bin/zkCli.sh -server 127.0.0.1:2181 ls path 查看节点 $ ls / create [-s] [-e] path data acl创建节点 $ # -s 顺序节点 $ # -e 临时节点 $ create -e /test 'ceshi' get path获取节点数据和更新信息 $ get /test delete path删除节点 $ delete /test 停止zk节点服务 $ ./zookeeper03/bin/zkServer.sh stop ","date":"2021-04-10","objectID":"/zookeeper-build/:7:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["zookeeper","distributed"],"content":"结语 以上是搭建zookeeper伪集群的全过程，真正集群的搭建也均类似。 ","date":"2021-04-10","objectID":"/zookeeper-build/:8:0","tags":["zookeeper","分布式协调组件"],"title":"Zookeeper集群搭建(伪集群)","uri":"/zookeeper-build/"},{"categories":["设计模式"],"content":"单例工厂模式","date":"2021-03-29","objectID":"/singleton-factory/","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"单例工厂模式确保一个类只有一个实例, 并提供一个全局访问点。 ","date":"2021-03-29","objectID":"/singleton-factory/:0:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"1 饿汉模式 /** * 饿汉模式 * * 优点: 线程安全，调用时效率高 * 缺点: 不管是否使用都创建对象，可能造成资源浪费 */ public class Hungry { private Hungry() { } private static Hungry hungry = new Hungry(); public static Hungry getInstance() { return hungry; } } ","date":"2021-03-29","objectID":"/singleton-factory/:1:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"2 普通懒汉模式 /** * 懒汉模式 * * 优点: 调用时才创建对象,不会浪费资源 * 缺点: 非线程安全 */ public class LazyNotSafe { private LazyNotSafe() { } private static LazyNotSafe lazyNotSafe; public static LazyNotSafe getInstance() { if (lazyNotSafe == null) { lazyNotSafe = new LazyNotSafe(); } return lazyNotSafe; } } ","date":"2021-03-29","objectID":"/singleton-factory/:2:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"3 加锁懒汉模式 /** * 加锁懒汉模式 * * 优点: 线程安全 * 缺点: 方法锁,效率较低 */ public class LazySync { private LazySync() { } private static LazySync lazySync; public static synchronized LazySync getInstance() { if (lazySync == null) { lazySync = new LazySync(); } return lazySync; } } ","date":"2021-03-29","objectID":"/singleton-factory/:3:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"4 双重检查锁 /** * 双重检查锁懒汉模式 * * 优点: 线程安全,效率较高 * * 注意：lazyDoubleLock对象需要加volatile关键字,禁止JVM指令重排,否则可能导致返回未创建好的对象 */ public class LazyDoubleLock { private LazyDoubleLock() { } private static volatile LazyDoubleLock lazyDoubleLock; public static LazyDoubleLock getInstance() { if (lazyDoubleLock == null) { synchronized (LazyDoubleLock.class) { if (lazyDoubleLock == null) { lazyDoubleLock = new LazyDoubleLock(); } } } return lazyDoubleLock; } } ","date":"2021-03-29","objectID":"/singleton-factory/:4:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"5 关于以上单例工厂实现的思考 以上单例工厂类或多或少存在部分问题, 主要以下2个问题: 反射攻击 可以禁止通过构造器实例化解决 序列化问题 java.io.ObjectOutputStream代表对象输出流,它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化,把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流,它的readObject()方法从一个源输入流中读取字节序列,再把它们反序列化为一个对象，并将其返回。 ","date":"2021-03-29","objectID":"/singleton-factory/:5:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"5.1 ObjectOutputStream源码 /** * Underlying writeObject/writeUnshared implementation. */ private void writeObject0(Object obj, boolean unshared) throws IOException { //...... //此处省略 // remaining cases if (obj instanceof String) { writeString((String) obj, unshared); } else if (cl.isArray()) { writeArray(obj, desc, unshared); } else if (obj instanceof Enum) { writeEnum((Enum\u003c?\u003e) obj, desc, unshared); } else if (obj instanceof Serializable) { writeOrdinaryObject(obj, desc, unshared); } else { if (extendedDebugInfo) { throw new NotSerializableException( cl.getName() + \"\\n\" + debugInfoStack.toString()); } else { throw new NotSerializableException(cl.getName()); } } //...... //此处省略 } 通过以上源码可知: String, Array, Enum不用实现Serializable接口, 其他情况下必须实现Serializable接口才能支持序列化; ","date":"2021-03-29","objectID":"/singleton-factory/:5:1","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"5.2 ObjectInputStream源码 /** * Reads and returns \"ordinary\" (i.e., not a String, Class, * ObjectStreamClass, array, or enum constant) object, or null if object's * class is unresolvable (in which case a ClassNotFoundException will be * associated with object's handle). Sets passHandle to object's assigned * handle. */ private Object readOrdinaryObject(boolean unshared) throws IOException { if (bin.readByte() != TC_OBJECT) { throw new InternalError(); } //...... //此处省略 Object obj; try { obj = desc.isInstantiable() ? desc.newInstance() : null; } catch (Exception ex) { throw (IOException) new InvalidClassException( desc.forClass().getName(), \"unable to create instance\").initCause(ex); } //...... //此处省略 if (obj != null \u0026\u0026 handles.lookupException(passHandle) == null \u0026\u0026 desc.hasReadResolveMethod()) { Object rep = desc.invokeReadResolve(obj); if (unshared \u0026\u0026 rep.getClass().isArray()) { rep = cloneArray(rep); } if (rep != obj) { // Filter the replacement object if (rep != null) { if (rep.getClass().isArray()) { filterCheck(rep.getClass(), Array.getLength(rep)); } else { filterCheck(rep.getClass(), -1); } } handles.setObject(passHandle, obj = rep); } } //...... //此处省略 return obj; } /** * Reads in and returns enum constant, or null if enum type is * unresolvable. Sets passHandle to enum constant's assigned handle. */ private Enum\u003c?\u003e readEnum(boolean unshared) throws IOException { if (bin.readByte() != TC_ENUM) { throw new InternalError(); } //...... //此处省略 String name = readString(false); Enum\u003c?\u003e result = null; Class\u003c?\u003e cl = desc.forClass(); if (cl != null) { try { @SuppressWarnings(\"unchecked\") Enum\u003c?\u003e en = Enum.valueOf((Class) cl, name); result = en; } catch (IllegalArgumentException ex) { throw (IOException) new InvalidObjectException( \"enum constant \" + name + \" does not exist in \" + cl).initCause(ex); } if (!unshared) { handles.setObject(enumHandle, result); } } //...... //此处省略 return result; } 通过以上源码可知: 对象反序列化时, 通过反射创建 对象反序列化时, 如果存在readResolve()方法, 则使用该方法返回的对象 枚举反序列化时, 本身保持单例 ","date":"2021-03-29","objectID":"/singleton-factory/:5:2","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"5.3 反射实例化源码 public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException { if (!override) { Class\u003c?\u003e caller = Reflection.getCallerClass(); checkAccess(caller, clazz, clazz, modifiers); } if ((clazz.getModifiers() \u0026 Modifier.ENUM) != 0) throw new IllegalArgumentException(\"Cannot reflectively create enum objects\"); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) { ca = acquireConstructorAccessor(); } @SuppressWarnings(\"unchecked\") T inst = (T) ca.newInstance(initargs); return inst; } 通过以上源码可知: 枚举不能通过反射实例化 ","date":"2021-03-29","objectID":"/singleton-factory/:5:3","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"5.4 结论 通过以上分析: 类中有readResolve()方法可以解决反序列化破坏 枚举是最完美的单例工厂模型 ","date":"2021-03-29","objectID":"/singleton-factory/:5:4","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"6 推荐单例工厂处理 ","date":"2021-03-29","objectID":"/singleton-factory/:6:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"6.1 静态内部类 /** * 静态内部类 * * 优点:线程安全,效率较高. */ public class StaticInner implements Serializable { private static final long serialVersionUID = 3676394038652350456L; private StaticInner() { // 构造器判断,防止反射攻击 if (InnerInstance.STATIC_INNER != null) { throw new IllegalStateException(); } } /** * 防止序列化攻击 */ private Object readResolve() throws ObjectStreamException { return InnerInstance.STATIC_INNER; } public static StaticInner getInstance() { return InnerInstance.STATIC_INNER; } private static class InnerInstance { private static final StaticInner STATIC_INNER = new StaticInner(); } } ","date":"2021-03-29","objectID":"/singleton-factory/:6:1","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"6.2 枚举 /** * 最完美的单例工厂模型 */ public enum EnumSingleton { INSTANCE; private final Object instance; EnumSingleton() { instance = new Object(); }; public Object getInstance() { return instance; } } ","date":"2021-03-29","objectID":"/singleton-factory/:6:2","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["设计模式"],"content":"7 单例工厂模式总结 饿汉模式 懒汉模式 加锁懒汉模式 双重锁检查 静态内部类 枚举 延迟加载 否 是 是 是 是 是 线程安全 是 否 是 是 是 是 高效 是 是 否 是 是 是 序列化安全 否 否 否 否 否 是 反射安全 否 否 否 否 否 是 如果对空间要求不高，可以用饿汉模式 懒汉模式由于非线程安全，加锁懒汉模式由于效率太低，一般不建议使用 一般来说，双重检查锁是用得较多的懒汉模式 静态内部类效果上跟懒汉模式差不多, 但更常见 枚举不管从代码量还是功能上讲，都是目前最推崇的单例模式，只是用习惯的人不多 ","date":"2021-03-29","objectID":"/singleton-factory/:7:0","tags":["设计模式","单例模式","单例工厂"],"title":"单例工厂模式","uri":"/singleton-factory/"},{"categories":["工作小札"],"content":"由于之前对mongo缺乏了解，在工作中，遇到了返回特定字段的内嵌查询场景，因此记录下此场景下的解决方案。 ","date":"2020-12-12","objectID":"/mongo-aggregation/:0:0","tags":["mongo"],"title":"Mongo内嵌数组按条件查询指定字段中的记录","uri":"/mongo-aggregation/"},{"categories":["工作小札"],"content":"背景 背景 例如一篇文章有多个评论，要筛选出满足特定条件的评论，但只返回评论字段。 { \"id\": \"xxx\", \"name\": \"测试的文章名\", \"comments\": [ { \"name\": \"用户名1\", \"type\": \"好评\", \"conteng\": \"评论的内容1\" }, { \"name\": \"用户名2\", \"type\": \"差评\", \"conteng\": \"评论的内容2\" }, { \"name\": \"用户名3\", \"type\": \"好评\", \"conteng\": \"评论的内容3\" } ] } 示例如上所示，但实际应用远比想象的复杂且量大。因此实际场景，只想返回指定的comments中满足条件的数据。 ","date":"2020-12-12","objectID":"/mongo-aggregation/:0:1","tags":["mongo"],"title":"Mongo内嵌数组按条件查询指定字段中的记录","uri":"/mongo-aggregation/"},{"categories":["工作小札"],"content":"解决方案 //1. 指定查询主文档 MatchOperation match1 = Aggregation.match(Criteria.where(\"id\").is(\"xxx\")); //2. 拆分内嵌文档(将数组中的每一个元素转为每一条文档) UnwindOperation unwind = Aggregation.unwind(\"comments\"); //3. 指定查询子文档 MatchOperation match2 = Aggregation.match(Criteria.where(\"comments.type\").is(\"好评\")); //4. 限制查询条数 LimitOperation limit = Aggregation.limit(1); //5. 指定投影，返回哪些字段 ProjectionOperation project = Aggregation.project(\"comments\"); //创建管道查询对象 Aggregation aggregation = Aggregation.newAggregation(match1, unwind, match2, limit, project); AggregationResults\u003cBasicDBObject\u003e results = mongoTemplate.aggregate(aggregation, \"t_table_name\", BasicDBObject.class); ","date":"2020-12-12","objectID":"/mongo-aggregation/:0:2","tags":["mongo"],"title":"Mongo内嵌数组按条件查询指定字段中的记录","uri":"/mongo-aggregation/"},{"categories":["工作小札"],"content":"Aggregation 数据通过条件限制传递到管道中的下一阶段，见Aggregation文档。以下是本解决方案中用到的限制条件： $unwind:将数组中的每一个元素转为每一条文档。 $match:过滤文档，条件查询。 $project:指定投影，返回指定字段。 $limit:限制返回查询条数。 ","date":"2020-12-12","objectID":"/mongo-aggregation/:0:3","tags":["mongo"],"title":"Mongo内嵌数组按条件查询指定字段中的记录","uri":"/mongo-aggregation/"},{"categories":["commands"],"content":"Git常用命令整理","date":"2020-11-25","objectID":"/git-common-commands/","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"Git常用命令整理. 注意 本文只包含对常用git命令的整理，后续会不定时更新…… ","date":"2020-11-25","objectID":"/git-common-commands/:0:0","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"ssh-keygen ssh-keygen -t rsa -C \"your email adress\" ","date":"2020-11-25","objectID":"/git-common-commands/:0:1","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git config # 配置用户名 git config --global user.name \"your name\" # 配置用户邮箱 git config --global user.email \"your email\" # 配置pull合并方式 git config --global pull.rebase false # 查看全局配置 git config --global --list # socks代理 git config --global http.proxy 'socks5://127.0.0.1:7890' git config --global https.proxy 'socks5://127.0.0.1:7890' # http代理 git config --global https.proxy 'http://127.0.0.1:7890' git config --global https.proxy 'https://127.0.0.1:7890' # 取消配置(例如取消代理配置) git config --global --unset http.proxy git config --global --unset https.proxy ","date":"2020-11-25","objectID":"/git-common-commands/:0:2","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git clone git clone \u003crepository\u003e # 递归拉取(一般用在仓库中有子模块的时候) git clone --recursive \u003crepository\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:3","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git branch # 查看本地分支列表 git branch -l # 查看远程分支列表 git branch -r # 查看本地+远程分支列表 git branch -a # 新建一个分支，但依然停留在当前分支 git branch \u003cbranchname\u003e # 现有分支与指定的远程分支建立追踪关系 git branch -u \u003cremote-branchname\u003e # 删除本地分支 git branch -d \u003cbranchname\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:4","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git add # 添加所有变化 git add . git add -A # 添加被修改，被删除的变化，不包括新增的文件 git add -u ","date":"2020-11-25","objectID":"/git-common-commands/:0:5","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git checkout # 切换到指定分支 git checkout \u003cbranch\u003e # 基于现有分支创建新分支，并切换至新分支 git checkout -b \u003cbranch\u003e # 基于远程分支创建新分支，并切换至新分支 git checkout -b \u003cbranch\u003e \u003cremote-branch\u003e # 恢复暂存区指定文件到工作区 git checkout \u003cfile\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:6","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git restore # 丢弃工作区指定文件的变化 git restore \u003cfile\u003e # 丢弃工作区所有变化 git restore . ","date":"2020-11-25","objectID":"/git-common-commands/:0:7","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git commit # 提交暂存区文件到仓库 git commit -m \u003cmessage\u003e # 提交至上个commit git commit --amend # 提交至上个commit(包括工作区的内容) git commit --amend -a ","date":"2020-11-25","objectID":"/git-common-commands/:0:8","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git tag # 列出所有tag git tag -l # 查看tag信息 git show \u003ctagname\u003e # 在当前commit新建一个tag git tag \u003ctagname\u003e # 在指定commit新建一个tag git tag \u003ctagname\u003e \u003ccommit\u003e # 推送指定tag至远程仓库 git push origin \u003ctagname\u003e # 推送所有tag至远程仓库 git push origin --tags # 删除本地tag git tag -d \u003ctagname\u003e # 删除远程tag git push origin :refs/tags/\u003ctagname\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:9","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git status # 显示所有变更的文件 git status ","date":"2020-11-25","objectID":"/git-common-commands/:0:10","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git log # 显示所有提交过的版本信息 git log --graph # 显示过去n次提交过的版本信息 git log -n # 根据关键词搜索提交历史 git log -S \u003ckeyword\u003e # 显示某个文件的版本历史，包括文件改动 git log --follow \u003cfile\u003e # 显示暂存区和工作区的差异 git diff # 显示两次提交之间的差异 git diff \u003ccommit1\u003e \u003ccommit2\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:11","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git reflog # 显示所有分支的操作记录，包括已经被删除的 commit 记录和 reset 的操作 git reflog git reflog -n ","date":"2020-11-25","objectID":"/git-common-commands/:0:12","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git reset # 回退至指定commit git reset --hard \u003ccommit\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:13","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git push # 推送本地分支至对应的远程分支 git push # 推送本地分支至指定的远程分支，并建立追踪 git push -u origin \u003cbranch\u003e # 强制推送 git push --force # 删除远程分支 git push origin --delete \u003cbranchname\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:14","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git pull # 拉取远程仓库的变化，并与本地分支合并 git pull ","date":"2020-11-25","objectID":"/git-common-commands/:0:15","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git fetch # 取回远程主机特定分支的更新 到 本地对应的远程分支 git fetch \u003cremote\u003e \u003cbranch\u003e # 创建并更新远程分支到本地远程分支。 git fetch # 手动指定了要fetch的remote。在不指定分支时通常默认为master git fetch \u003cremote\u003e 警告 pull:拉取远程仓库的变化到本地远程分支，并与本地分支合并 fetch:拉取远程仓库的变化到本地远程分支，但不与本地分支合并 ","date":"2020-11-25","objectID":"/git-common-commands/:0:16","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git remote # 显示所有远程仓库 git remote -v # 把本地仓库和远程仓库关联 git remote add origin \u003crepository\u003e ","date":"2020-11-25","objectID":"/git-common-commands/:0:17","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git submodule # 添加子模块 git submodule add \u003crepository\u003e \u003cpath\u003e # 初始化子模块 git submodule init # 更新子模块 git submodule update # 拉取所有子模块 git submodule foreach git pull ","date":"2020-11-25","objectID":"/git-common-commands/:0:18","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":["commands"],"content":"git rebase # 合并当前commit到指定commit的记录 git rebase -i \u003ccommit\u003e 如何选择 git rebase 或 git merge ? 以下是2种合并方式的比较: merge:使用简单，但每次合并时会生成一个新的合并点；merge操作遇到冲突的时候，当前merge不能继续进行下去。手动修改冲突内容后，add修改，commit就可以继续往下操作。 rebase:操作稍微复杂，会把你当前分支的 commit放到公共分支的最前面(靠近HEAD)；rebase操作遇到冲突的时候会中断rebase，同时会提示去解决冲突。解决冲突后，将修改add后执行git rebase —-continue继续操作，或者git rebase —-skip忽略冲突。 一般推荐使用rebase，因为merge之后会有记录，然后在提交PR(Pull/Request)会很难看。 关于fork了别人的仓库，如何保持同步更新? 给fork配置一个remote 使用git remote -v查看远程状态 添加一个将被同步给fork远程的上游仓库(源名称一般建议upstream，可修改) git remote add upstream \u003cgit address\u003e 再次通过git remote -v查看状态确认是否配置成功 同步至fork 从上游仓库fetch分支和提交点，传送至本地，并会被存储在一个本地分支upstream/master git fetch upstream 切换到本地主分支 git checkout master 把upstream/master分支合并到本地master上，这样就完成了同步，并且不会丢掉本地修改的内容 git rebase upstream/master 最后一步git push origin master 强烈推荐使用rebase，因为merge之后会有记录，然后在提交PR(Pull/Request)会很难看。 ","date":"2020-11-25","objectID":"/git-common-commands/:0:19","tags":["git"],"title":"Git常用命令整理","uri":"/git-common-commands/"},{"categories":null,"content":" 笔名: imicrocode，非著名码农。 生于1993年，籍贯湖北仙桃，现居湖北武汉。目前就职于某互联网软件服务公司。 Java开发界的小学生。 个人爱好 热爱编程，热爱技术，相信技术改变生活。喜欢阅读优秀框架源码，学习其设计模式及编程技巧。 喜欢记笔记，记录分享传播工作中学习到的知识，分享给同样热爱技术的人儿。 宗旨 本博客主要分享本人在日常工作中遇到的实际问题和学习中读过的好文，及企业应用架构实践中非常实用的干货内容。希望通过博客文章，将知识分享给大家。 意见反馈 若本网站内容有做得不到位的地方（比如：涉及版权或其他问题），请及时联系我进行整改。 联系方式 暂无 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于博主","uri":"/about/"}]